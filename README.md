# Кривошеев Максим УИБО-14-24
# Алгоритмы сортировки и поиска
## 1.Сортировка выбором.
Сортировка выбором (Selection Sort) — это простой алгоритм сортировки, который последовательно находит минимальный элемент в несортированной части массива и перемещает его в начало отсортированной части. Этот процесс повторяется до тех пор, пока весь массив не станет отсортированным.
#### Объяснение работы алгоритма:
1) Инициализация: Массив рассматривается целиком как несортированная область.
2) Проход по массиву: Начинаем с первой позиции массива и последовательно перемещаемся вправо.
3) Нахождение минимума: Для каждой итерации находим наименьший элемент в оставшейся части массива.
4) бмен местами: Найденный минимум обмениваем с первым элементом текущей несортированной области.
Переход к следующей итерации: Уменьшаем размер несортированной области на одну позицию, повторяя шаги 2-4.
#### Временная сложность: 
Время работы алгоритма определяется количеством сравнений и замен.

**Количество проходов:** Необходимо пройти по всему массиву (n) раз, и на каждом этапе искать минимальное значение среди оставшихся элементов.

**Количество сравнений:** Для каждого прохода требуется сравнить текущий элемент с остальными элементами массива. Следовательно, общее число сравнений приблизительно равно n^2/2.

**Замены:** Каждое перемещение требует одной операции замены, и в общей сложности выполняется n замещений.

Таким образом, итоговая временная сложность алгоритма равна: O(n^2).

Эта оценка справедлива как для лучшего случая (массив уже отсортирован), среднего случая (случайные данные), так и для худшего случая (обратный порядок элементов).
## 2.Сортировка обменом.
Сортировка обменом (Bubble Sort) — это простой алгоритм сортировки, который многократно проходит по списку, сравнивая смежные элементы и меняя их местами, если они находятся в неправильном порядке. Этот процесс повторяется до тех пор, пока весь список не будет отсортирован.
#### Объяснение работы алгоритма:
1) Инициализация:
n = len(arr) — получаем длину массива.
Внешний цикл for i in range(n - 1) выполняется n-1 раз (достаточно для сортировки, так как последний элемент автоматически займет свое место).
2) Внутренний цикл и проверка:
swapped = False — флаг, который отслеживает, были ли обмены во внутреннем цикле.
Внутренний цикл for j in range(n - i - 1) проходит по неотсортированной части массива (после каждого прохода самый большой элемент "всплывает" в конец).
Сравниваются соседние элементы arr[j] и arr[j + 1]. Если arr[j] > arr[j + 1], они меняются местами, и swapped устанавливается в True.
3) Оптимизация:
Если во внутреннем цикле не было ни одного обмена (swapped остался False), массив уже отсортирован, и алгоритм досрочно завершает работу (break).
#### Временная сложность: 
**Худший случай:** O(n^2), где n — количество элементов массива. Это происходит тогда, когда массив отсортирован в обратном порядке, и каждый элемент приходится сравнивать и перемещать почти со всеми остальными элементами.

**Средний случай:** также O(n^2). Поскольку алгоритм требует сравнения каждого элемента практически со всеми последующими элементами, среднее число сравнений примерно равно квадрату размера массива.

**Лучший случай:** O(n) (линейная сложность). Такой случай возникает, если массив изначально отсортирован. Тогда первый проход завершится без обменов, и алгоритм остановится досрочно благодаря флагу swapped.
## 3.Сортировка вставками.
Сортировка вставками (Insertion Sort) — это простой алгоритм сортировки, который работает путем постепенного построения отсортированной части массива. На каждом шаге новый элемент вставляется в уже отсортированную часть массива на своё правильное место.
#### Объяснение работы алгоритма:
1) Предположение: Начнём с того, что первый элемент массива уже отсортирован.
2) Выбор элемента: Берём следующий элемент массива и сравниваем его с элементами в уже отсортированной части.
3) Вставка: Если текущий элемент меньше какого-либо элемента в отсортированной части, сдвигаем большие элементы вправо, создавая свободное место для вставки текущего элемента.
4) Повторение: Повторяем этот процесс для каждого последующего элемента, пока весь массив не будет отсортирован.
#### Временная сложность:
**Лучшая ситуация (массив уже отсортирован):** O(n), потому что элементы не требуют перемещения.

**Средняя и худшая ситуации (характерны для произвольного массива):** O(n^2), так как для каждого элемента может потребоваться просмотр всей предыдущей части массива.

Хотя временная сложность хуже, чем у некоторых продвинутых алгоритмов (например, быстрая сортировка или сортировка слиянием), сортировка вставками полезна для маленьких массивов или почти отсортированных данных.
## 4.Сортировка слиянием.
Сортировка слиянием (Merge Sort) — это эффективный алгоритм сортировки, который использует принцип "разделяй и властвуй". Он работает путём разделения массива на две половины, сортировки каждой половины рекурсивно и последующего объединения двух отсортированных половин в один отсортированный массив.
#### Объяснение работы алгоритма:
1)Разбиение массива: Массив делится на две примерно равные части.
2)Рекурсия: Каждая половина снова делится на две части, и этот процесс продолжается до тех пор, пока каждая часть не станет содержать один элемент (один элемент автоматически считается отсортированным).
3)Объединение: Две отсортированные части объединяются в один отсортированный массив. Это объединение происходит путём сравнения элементов из обеих частей и выбора меньшего из них для добавления в результирующий массив.

Сортировка слиянием основана на принципе "разделяй и властвуй": массив делится на две равные половины, каждая половина рекурсивно сортируется отдельно, а затем обе половинки сливаются обратно вместе в правильном порядке.
#### Временная сложность:
**Разбиение массива:** Каждое деление массива уменьшает его размер вдвое. Следовательно, глубина рекурсии равна O(logn).

**Обработка на уровне объединения:** За каждую операцию слияния потребуется просмотреть все элементы, что даёт сложность O(n).

Таким образом, общая временная сложность Merge Sort равна произведению глубины рекурсии и стоимости обработки на одном уровне: O(nlogn).
## 5.Сортировка Шелла.
Сортировка Шелла — это алгоритм сортировки, который является обобщением сортировки вставками. Он сортирует элементы, сравнивая и перемещая элементы, находящиеся на определенном расстоянии друг от друга (шаг), постепенно уменьшая этот шаг до единицы. Это позволяет сначала устранить массовые нарушения порядка, что повышает эффективность финальной сортировки вставками.
#### Объяснение работы алгоритма:
1)Выбор шага: начальный шаг вычисляется как n/2, где n — размер массива. На каждой итерации шаг уменьшается вдвое, пока не станет равным 1.
2)Сортировка вставками с шагом: для каждого шага алгоритм выполняет сортировку вставками, но сравнивает и перемещает элементы, находящиеся на расстоянии step, а не соседние. Это позволяет элементам быстрее занимать правильные позиции.
3)Уменьшение шага: процесс повторяется с уменьшением шага, пока step не станет равным 1. На этом этапе массив почти отсортирован, и финальный проход с шагом 1 завершает сортировку.

Алгоритм Shell Sort является усовершенствованной версией обычной сортировки вставками (Insertion Sort) путем добавления промежуточных шагов («шагов») перед полной финальной сортировкой. Основная идея заключается в том, чтобы сначала упорядочить массив большими интервалами ("gap"), постепенно уменьшая размер интервала до единичного значения. Это позволяет существенно повысить эффективность алгоритма по сравнению с простой сортировкой вставками.
#### Временная сложность:
Временная сложность алгоритма Shell Sort напрямую зависит от двух факторов:
1. Выбор последовательности шагов (gap sequence): От выбора конкретной последовательности шагов, используемых в процессе сортировки, зависит количество сравнений и перемещений элементов. Чем лучше выбрана последовательность шагов, тем эффективнее алгоритм.
2. Также временная сложность зависит от исходного состояния массива:
Лучшая ситуация: Массив почти отсортирован. Тогда каждое перемещение минимально влияет на общий порядок, и временные затраты приближаются к O(nlogn).
Хуже всего: Массив отсортирован в обратном порядке. Здесь количество перестановок и сравнений увеличивается, и временная сложность стремится к O(n2). Хотя даже в худшем случае Shell Sort зачастую превосходит обычную сортировку вставками.
## 6.Быстрая сортировка.
Быстрая сортировка — это эффективный алгоритм сортировки, использующий стратегию "разделяй и властвуй". Алгоритм выбирает опорный элемент (pivot), разделяет массив на две части: элементы меньше опорного и элементы больше опорного, затем рекурсивно сортирует обе части.
#### Объяснение работы алгоритма:
1) Выбор опорного элемента (pivot): в данном коде выбирается последний элемент массива, но можно выбирать первый, средний или случайный элемент.
2) Разделение (partition): переставляем элементы так, чтобы все элементы меньше опорного оказались слева, а больше — справа. Используется два указателя: i (индекс последнего элемента в "меньшей" части) и j (текущий элемент). В конце цикла опорный элемент помещается на правильную позицию.
3) Рекурсия: рекурсивно применяем быструю сортировку к левой части (элементы < pivot). Рекурсивно применяем к правой части (элементы > pivot).
#### Временная сложность:
**Лучший случай (O(n log n)):**
Это происходит тогда, когда каждый раз опорный элемент выбирает идеальное разделение массива почти пополам. Тогда глубина рекурсии составит log₂n, и на каждом уровне потребуется линейное количество операций (O(n)). Таким образом, общая временная сложность составляет O(n log n).

**Средний случай (O(n log n)):**
Даже если среднее положение опорного элемента не идеально, в большинстве случаев распределение элементов оказывается достаточно равномерным, обеспечивая среднюю производительность порядка O(n log n).

**Худший случай (O(n²)):**
Хуже всего ситуация возникает, когда выбранный опорный элемент постоянно находится на краю массива (самый маленький или самый большой элемент). Это приведет к последовательному уменьшению размера одной стороны на единицу, создавая глубокую рекурсию глубиной порядка n уровней. Такое случается редко, особенно если выбрать хороший способ выбора опорного элемента (например, рандомизировать выбор).

Однако даже несмотря на худшие случаи, быстрая сортировка чаще всего используется благодаря своей эффективности в среднем и её хорошей производительности на реальных данных.
## 7.Пирамидальная сортировка.
Пирамидальная сортировка — это алгоритм сортировки, основанный на структуре данных "двоичная куча". Алгоритм состоит из двух этапов: построение пирамиды (кучи) из исходного массива и последовательное извлечение максимальных элементов с перестройкой кучи.
#### Объяснение работы алгоритма:
Построение кучи (heapify):
1) Преобразуем массив в максимальную кучу, где каждый родительский узел больше своих дочерних.
2) Начинаем с последнего нелистового узла (индекс n/2 - 1) и движемся к корню.
Сортировка:
1) Максимальный элемент находится в корне (индекс 0).
2) Меняем корневой элемент с последним элементом массива.
3) Уменьшаем размер кучи на 1 и перестраиваем кучу для корня.
4) Повторяем процесс, пока в куче не останется один элемент.
#### Временная сложность:
Создание начальной кучи: O(N)

Извлечение каждого элемента и восстановление кучи: каждая операция heapify занимает O(logN), а таких операций N штук, следовательно общая сложность: O(N⋅logN)

Это значит, что независимо от порядка элементов в начальном массиве, сортировка будет выполняться за O(NlogN) операций, что лучше, чем у многих простых методов сортировки вроде пузырьковой или вставок. Однако, Heap Sort уступает другим методам типа быстрой сортировки (Quick Sort) в плане скорости на практике из-за большего количества необходимых обменов памяти.
## 8.Последовательный поиск.
Последовательный поиск — это простейший алгоритм поиска элемента в массиве или списке, при котором каждый элемент последовательно проверяется на соответствие искомому значению, начиная с начала структуры данных.
#### Объяснение работы алгоритма:
1)Начало: алгоритм начинает с первого элемента массива (индекс 0).
Сравнение: сравнивает текущий элемент с искомым значением.
2)Результат: если элементы совпадают - возвращает индекс текущего элемента.
3)Продолжение: если не совпадают - переходит к следующему элементу.
4)Завершение: процесс повторяется до тех пор, пока: Не будет найден искомый элемент или не будет достигнут конец массива (в этом случае возвращается -1).
#### Временная сложность:
O(1) для итеративной версии, O(n) для рекурсивной.
## 9.Бинарный поиск.
Бинарный поиск — это эффективный алгоритм поиска элемента в отсортированном массиве путём последовательного деления массива пополам и выбора нужной половины, пока элемент не найден либо область поиска не станет пустой.
#### Объяснение работы алгоритма:
Алгоритм бинарного поиска состоит из следующих шагов:
Инициализация: Определяются границы области поиска (left и right), соответствующие началу и концу массива соответственно.
Средняя точка: Вычисляется средняя позиция массива (mid = left + (right-left)/2) и проверяется значение элемента на этой позиции.
Проверка условия: Если искомый элемент равен значению среднего элемента, значит, поиск завершён успешно.
1) Если искомое число меньше значения в средней точке, тогда рекурсивно повторяем процесс для левой части массива (right = mid — 1).
2) Если искомое число больше значения в средней точке, тогда аналогично рассматриваем правую половину массива (left = mid + 1).
Итерация продолжается, пока граница слева не превышает границу справа. Если нужный элемент не обнаружен после завершения итераций, возвращаем индикатор неудачи (например, индекс -1).
#### Временная сложность:
Временная сложность бинарного поиска составляет O(logn)

Это связано с тем, что на каждой итерации алгоритма область поиска уменьшается ровно наполовину. Поэтому общее количество проверок, необходимых для нахождения элемента, пропорционально двоичному логарифму от размера массива.
## 10.Интерполирующий поиск.
Интерполирующий поиск — это улучшенный вариант классического бинарного поиска, предназначенный для равномерных распределённых данных. Этот алгоритм пытается предсказать местоположение искомого элемента внутри отсортированного массива, используя формулу интерполяции, основанную на относительном положении текущего ключа относительно первых и последних элементов массива.
#### Объяснение работы алгоритма:
1)Выбор начальной позиции: используя формулу интерполяции, выбираем позицию, близкую к ожидаемой позиции искомого элемента.
2)Проверка выбранного элемента: если выбранный элемент равен искомому, поиск успешен. Если искомый элемент больше, обновляем нижнюю границу (low) и продолжаем поиск дальше. Если искомый элемент меньше, обновляем верхнюю границу (high) и сужаем область поиска.
3)Повторение цикла: процесс повторяется, пока диапазон поиска не сузится до пустоты (когда нижняя граница превысила верхнюю).
Реализация:
1) Мы инициализируем границы поиска:int low = 0;int high = size - 1;
2) Затем запускается основной цикл, продолжающийся до тех пор, пока ключ лежит в диапазоне текущих границ:while((arr[high] >= key && arr[low] <= key))
3) Вычисляем приблизительную позицию ключа:int pos = low + (((double)(high - low) / (arr[high] - arr[low])) * (key - arr[low]))Формула выглядит сложной, но смысл прост: мы используем соотношение расстояния между крайними элементами массива и расстоянием между ключом и минимальным элементом, чтобы предсказать положение искомого элемента.
4) Проверяем, соответствует ли элемент заданному ключу:if (arr[pos] == key)    return pos;
5) Если элемент оказался меньше, смещаем нижнюю границу вверх:if (arr[pos] < key)    low = pos + 1;
6) Если элемент оказался больше, смещаем верхнюю границу вниз:else    high = pos - 1;
7) После окончания основного цикла проверяется последний элемент:if (arr[low] == key)    return low;
8) Если ничего не найдено, возвращается -1.
#### Временная сложность:
Временная сложность интерполирующего поиска сильно зависит от характера распределения данных:

**При равномерном распределении** (идеальная ситуация) среднее время поиска — около O(loglogN), что делает его одним из наиболее эффективных методов поиска.

**Для произвольных данных или неравномерно распределённых массивов** (например, если данные кластеризованы) временная сложность может ухудшиться вплоть до O(N), что эквивалентно обычному линейному поиску.

Интерполирующий поиск особенно хорош для больших однородных данных, где распределение ключей близко к равномерному.
## 11.Фибоначчи поиск.
Фибоначчи-поиск — это разновидность двоичного поиска, использующая последовательность чисел Фибоначчи для эффективного нахождения заданного элемента в отсортированном массиве. Основное отличие от стандартного бинарного поиска заключается в том, что вместо простого деления массива пополам, Фибоначчи-поиск делит массив на части, размеры которых соответствуют двум соседним числам Фибоначчи.
#### Объяснение работы алгоритма:
Проверяется условие на значение параметра n:
1) Если n≤0n≤0, возвращается пустой список.
2) Если n=1n=1, возвращается список [0], содержащий одно число.
3) Если n=2n=2, возвращается список [0,1], содержащий два числа.

Для n>2n>2 создаётся начальная последовательность [0,1]. Затем циклом выполняется последовательное вычисление последующих членов ряда, начиная с третьего (i=2)(i=2).

Внутри цикла на каждой итерации новое число добавляется в конец списка путём суммирования двух последних элементов последовательности.
#### Временная сложность:
Для анализа временной сложности рассмотрим основные операции:
Количество операций внутри основного цикла зависит от значения n.
1) Каждый новый элемент рассчитывается за константное время путем простой арифметической операции (сложение).
2) Добавление нового элемента в конец списка также занимает константное время (операция append() в Python работает за O(1)).

Следовательно, общее количество шагов (итераций цикла) прямо пропорционально значению n. Таким образом, временная сложность алгоритма линейна и равна O(n).
